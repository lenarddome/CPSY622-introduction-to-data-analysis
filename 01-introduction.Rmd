---
bibliography: biblio.bib
---

# (PART) Foundations {-}

# Quantitative Research

> One of the many goals of quantitative methods is to make reliable conclusions from the observations you make. 

There are many radically different ways to acquire and analyse data.
From the traditional, mainstream psychology perspective, there is a well-tried formula on how you should go about it.
Its goal is to test explanations of behaviour and cognition — to narrow down the vast number of hypothesis you can build to explain human cognition and behaviour.
If you are a behavioural scientist, a rudimentary and user-friendly scientific method might look like this:

* Hypothesis: Given condition X, we will see people do Y.
* Measurement: Make observations under condition X.
* **Test: Did we observe people do Y?**

I would like to emphasize that this is a rudimentary, straightforward empirical test of a given explanation.
It can be a powerful tool, but surprisingly ineffective.
In an ideal scenario, you want at least two different and contradictory hypotheses.

* $H_1$: Given condition X, we will see people do Y.
* $H_2$: Given condition X, we will see people do Z.
* $H_3$: Given…
* $H_4$: Given…

Hypotheses can be slightly different or directly contradicting each other.
No matter how similar might be, distinguishing between these hypothesis allow us to infer often subtle ways a certain psychological process might operate.
Nonetheless, this is only one of the countless ways science can be carried out.
We will stick with the rudimentary version of our scientific method.

## Hypothesis: Given condition X, we will see people do Y.

Researchers conjure hypothesis after taking a set of assumptions about how humans work.
That is to say, they look at the consequences of laws of behaviour and cognition[^implicit].
Consider one such law established by Adam Smith:

> People make rational choices based on their self-interest.

This idea is part of expected utility theory — a normative approach to decision-making.
One consequence of this law is that people will always pick the choice that will have the highest reward with the highest certainty.

## Measurement: Make observations under condition X.

In order to test hypotheses, we have to record what people have done under condition X.
This is usually done by measuring some aspect of behaviour: choices, eye movement, reaction times, self-reports, …
Remember that the assumption we just made is that people are rational.
This means that they should pick the option with the highest possible reward.
A simple test of rationality involves asking people to pick between options with different rewards.

For example, @kahneman1979prospect presented people with scenarios varying in levels of risks and asked them to make choices.
Before we look at two problems from their study, 
Now let us look at **Problem 5** and **Problem 6** from their study.

**Problem 5** is presented below with the 2 choice options. It had N=72 participants. Choice proportions are in parentheses.

* A: 50% chance to win a three-week tour of England, France, and Italy. (22%)
* **B: A one-week tour of England, with certainty. (78%)**

So, 22% took a gamble on the long trip, while about 3.55 times as many people picked the certain outcome.
Compare this result with **Problem 6**:

* **C: 5% chance to win a three-week tour of England, France, and Italy. (67%)**
* D: 10% chance to win a one-week tour of England. (33%)

This is a sufficiently surprising result[^prospect] to make us reevaluate our assumption that people make rational choices.
@kahneman1979prospect came up with [Prospect Theory](https://en.wikipedia.org/wiki/Prospect_theory) to explain both when people are rational and when they are not.

## **Test: Did we observe people do Y?**

If you look back at the results we just presented, it is simple enough to interpret.
It gives a good and shallow overview of how you end up with some data.
Unfortunately, it is often not this easy.
Imagine a twist on this scenario, where you are interested in how people suffering from addiction weigh in possible losses and gains.
We know that people suffering from substance-abuse disorders have a problem with reward processing [@gueguen2021computational].
So we can come up with a hypothesis that people suffering from substance-abuse disorder will be more likely to pick the worst option.
If you want to measure it, you formulate new problems with two options, and test both healthy adults and adults suffering from substance-abuse.
You collect your data and then look at the proportions of people picked one over the other in each group (healthy vs substance-abuse).

In order to confirm or contradict our impromptu hypothesis, you are required to reliably conclude that the groups perform the same/different from the data (observations) you have.
This is where data analysis (and R) comes in.

# Why statistics?

While human reasoning is powerful, it is influenced by human biases, limited cognitive capacity, and also by simple tiredness.
It is actually hard to evaluate evidence without pre-existing beliefs.

## Biases are unavoidable

@evans1983conflict

## Data has always more things to tell us

@bickel1975sex Simpson's Paradox

# Reproducibility Backlash

One of the most important endeavours that science as a social enterprise can engage is to verify each other's observations through independent replications.
The reason behind this is simple: repeated observations will increase our confidence that the effect is real.

## Reproducibility Crisis

<center>
<figure>
<img src="./assets/replication-crisis.png" width="500" alt="Reproducibility numbers" /></a>
<figcaption> Image was taken from [Open Science Collaboration (2015)](https://doi.org/10.1126/science.aac4716) </figcaption>
</figure>
</center>

## Some causes we can fix by changing how we do and document our analysis

1. Misunderstanding of statistics
2. Low reproducibility (experiments, **analysis**)
3. Poor records
4. Not sharing data openly

* Andy Wills: Fix the replication Crisis [video](https://www.youtube.com/watch?v=_OqiTVq12Pk)

* David Shanks: The replication crisis in psychology [video](https://www.youtube.com/watch?v=Zz627CecmgU)

* David Shanks: Does social science tell the truth? [video](https://www.youtube.com/watch?v=Jt7gEAoUl8s)

* Priya Silverstein: Easing into open science [video](https://www.youtube.com/watch?v=owJaD3UiseQ)

# Open Science

# Why R?

* Free as in Freedom

> Costs £0.

* Documents your analysis

> Any conclusion people make from data should stand independent of the person making
> the conclusion.

* Open Source

> If you do the same tests on the same data, but get a different result, the difference must be about how the authors programmed the test.

* Data preprocessing

> People roughly spend 80% of their time on data preprocessing, see [article](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#5e7ed02f6f63).
> R is superb at preprocessing, saving a large amount of time — especially for multiple projects.

* Danielle Navarro: R for Psychological Science? [video](https://www.youtube.com/watch?v=xFkEbYk0C0Q)

# (PART) Design {-}

# Project Design

# Analysis Pipeline

**The published paper is only a summary of what you have done, it is not the perfect
record of how you arrived at a certain statistical conclusion.**

Using R allows you to complement your paper. It will let you:

* Records every analysis step.
* Inspect the way how your peers calculated the results.
* Reproduce analysis and let others reproduce yours.

[Some reasons to use R](https://www.andywills.info/rminr/why-r-student.html)

# Reproducibility

# Archives

[^prospect]:
It is also important to note that this is not a one-off.
There are large-scale replications of this behavioural tendency to pick the riskier choice when there is a high chance of loss [@ruggeri2020replicating].

[^implicit]:
Unfortunately, these assumptions often remain implicit and are not stated explicitly.
Hypotheses are the offspring of our understanding of how humans work.
Therefore, it is important to explicitly state how we think humans work if we want to further our understanding.